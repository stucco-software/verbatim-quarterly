{
  "type": "Article",
  "title": "Redundancy in Natural Languages",
  "author": "Steve Bonner",
  "location": "Germantown, Maryland",
  "html": "<link rel=\"type\" href=\"Article\"><h1 data-rel=\"title\">Redundancy in Natural Languages</h1>\n<p><em><span data-rel=\"author\">Steve Bonner</span> <span data-rel=\"location\">Germantown, Maryland</span></em></p>\n<p>In this fast-paced age when information is digitized,\nfaxed, uplinked, and downloaded, it is appropriate\nto consider natural languages from the\npoint of view of information theory.  That is, we examine\nthe information content of text or messages\nand the efficiency with which that information is\nrepresented.  The idea here is not to convert language\ninto some sort of highly efficient, but inhuman,\nstream of ones and zeroes!  That type of efficiency\nis fine for computers, but not for human\nbeings.  In fact, as we shall see, natural languages\ncontain a fair amount of redundancy.  While this\ndoes not provide us with the most concise form of\ncommunication possible, it is a form that is ideally\nsuited to human experience, which, after all, is why\nit came to be as it is.</p>\n<p>It cannot be denied that some words are simply\nlonger than they strictly need to be.  This is perhaps\nmore noticeable in German than in English.  In German,\nas new words are needed, they are often\nformed from smaller words already existing.  Thus,\nwe have the words <em>Haupthandelsartikel</em>, meaning\n'staple,' and <em>Autoreparaturwerkstatt</em>, meaning 'garage.'\nIf we were to construct a new vocabulary\nfrom scratch from the point of view of an extremely\norderly, but over-zealous, cataloguer, we might\nhave as the first two words in our dictionary <em>AAAA</em>\nand AAAB.  We would continue in this manner until\nwe reached our last two words, <em>ZZZY</em> and <em>ZZZZ</em>.\nOur dictionary would contain 456,976 words.  This\nlexicon is of sufficient size to form a rich written\nlanguage, such as German or English.  In fact, we\ncould associate to each English word one of our new\nwords.  Thus, the phrase <em>To be, or not to be</em>?  might\nbecome <em>THJL BDMN, OQRA NOOP THJL BDMN?</em>\n(So much for pronounceability!)  Of course, in this\nexample, our two-letter words become four-letter\nwords, which hasn't helped keep things concise.  But\nnow there is no word longer than four letters.  This\ngame of re-cataloguing all our words undoes a natural\nprocess which occurs as languages evolve.  This is\nthe tendency to shorten frequently used words and\nto allow less frequently used words to become\nlonger.  This trend, known as <em>Zipf's Law</em>, causes\ncommon words such as <em>to, in, a</em>, and it to be as short\nas they are.  It would be unthinkable to replace\nthese with ten-letter variants!  In this way, language\nat least attempts to follow a path of least resistance,\nin which the effort expended in writing or speech is\nlessened.</p>\n<p>Despite the economies of effort introduced by\nZipf's Law, natural languages nonetheless contain\nredundancies.  One example is the indefinite article\n<em>a</em> in English.  Many languages are inflected, which is\nalso a form of redundancy, since English gets by\nnicely with little inflection.  In English, the function\nof words within sentences is typically signaled by\nword order.  The sentences <em>I threw the dog the ball</em>\nand <em>I threw the ball the dog</em> are not equivalent.\nHere, some of the semantic information is provided\nby word order, and not simply from the words themselves.\nIn an inflected language, endings affixed to\nthe words for <em>dog</em> and <em>ball</em> indicate which object is\ndirect and which is indirect.  Thus, it is possible to\nrearrange words as in the example above.  The result\nmay not always be idiomatic, but it will probably get\nthe point across.  Such flexibility allows for a greater\ndegree of expression in poetry, for example.  Thus,\none has a romantic poem written in Latin in which\nthe first line contains the words for <em>man</em> and <em>woman</em>\non opposite ends of the line.  By the end of the\npoem, the words have gravitated toward the middle\nof the line.  It can even be argued that word forms\nused to show tense are superfluous, since Chinese\nhas no notion of tense.  A sentence may be in the\npast, present, or future, depending on context.  One\nwonders how a person translating into Chinese\nwould deal with unexpected or unpredictable tense\nshifts: <em>Veni, video, vincam!</em></p>\n<p>Not only does the degree of redundancy vary\nfrom language to language, but also from one writing\nstyle to another.  One author might have a more loquacious\nbent than another.  Neither author can be\nsaid to have the better style.  A lengthy passage, if\nwritten well, can be more expressive and have\ngreater effect than a simple, one-line statement of\nfact.  On the other hand, brevity is what gives a pithy\naphorism its strength.  This is true of both poetry\nand prose.  More so than prose, however, poetry\ntends to explore both extremes—the concise and\nthe protracted.  Poe, for example, used repetition in\nhis poem <em>The Bells</em> to convey to the reader a sense of\nactually hearing the tolling of the bells, as though\nthe sounds themselves were imprinted on the page.\nSomehow, it would not have been the same had Poe\nwritten simply that “The bells rang a lot.”  Or\n“bells, bells, et cetera.”  At the other extreme, some\npoets attempt to carefully choose words in such a\nway that the poem expresses a great deal in very\nlittle space.  Thus, we have a verse form like haiku,\nin which the totality of the poem is condensed into\nonly seventeen syllables.  If only certain genres of\nprose could be as succinct!  A never-ending meeting\nat the office could be completed in plenty of time for\na coffee break.  Presidential debates could begin and\nend with the introductory niceties, since very little\nof substance is ever said.  The civilized world would\nbe grateful indeed if lengthy advertising pitches\nwere instead given in haiku:</p>\n<blockquote>\n<p>Sudzo detergent<br>\nClean white garments full of fluff<br>\nBuy many boxes</p>\n</blockquote>\n<p>Notwithstanding certain benefits arising from\ncompactness, redundancy actually plays an important\nrole in the communication process.  One is reminded\nof an experiment in which two subjects\nwere placed in separate rooms and allowed to communicate\nonly through a teletype.  One person was\ngiven a box of parts to a wheelbarrow, as provided\nfrom the factory (“some assembly required”).  The\nother was given the assembly instructions.  The object\nwas to successfully assemble the wheelbarrow.\nSentences transmitted usually read something like\nPut bolt into L-shaped part.  Such an imperative\nmight elicit the response Which bolt?  or  Which L?\nOr perhaps the recipient of the message would insert\nsome bolt into some part, only to find later that\na needed part had already been attached.  When the\ntest is modified to allow phone conversation, the\ntime required for assembly decreases dramatically.\nPhrases become more verbose and more redundant,\nbut more communicative.  With very little effort, it\nis possible to utter a terrific run-on sentence like,\n“Put the medium-sized brass bolt—not the one with\nthe little black top, but the other one—into the sort\nof oblong L-shaped part with the green paint on one\nend, but first make sure that you have the axle\npointed towards the side with the sort of wooden\nhandle.”  A person would not be inclined to type out\nsuch a message verbatim.  More likely, he would remove\noccasional words deemed to be redundant.\nBut in the process, the sentence would become less\ncolloquial and less intelligible.</p>\n<p>The presence of redundancy in language is perhaps\nbest observed when the communication process\nbreaks down.  The fact that a deaf person can\ndetermine a spoken phrase by reading lips demonstrates\nthat the information is simultaneously being\nconveyed in two different ways.  Those with normal\nhearing can use visual clues to assist during the listening\nprocess.  Thus, it is possible to pick out the\nnecessary morsels of information in noisy surroundings,\nif facial expressions, gestures and other contextual\nclues are taken into account.  But even in the\nabsence of visual clues, the very sounds of human\nspeech are overflowing with many times the volume\nof data strictly required to convey the message.  Examining\na graph of a simple speech component, such\nas the sound of a vowel, one sees a complex pattern\nof superimposed waves, having myriad peaks and\nvalleys.  When such a pattern is recorded and stored\nin computer-readable (“digitized”) form, it occupies\nan inordinately large amount of storage.  This seems\nall the more wasteful, considering that the only useful\ninformation being conveyed in our example is a\nsingle vowel sound.  This apparent redundancy,\nonce again, proves to be beneficial.  Conversing over\na noisy telephone line would be impossible were it\nnot for the complexity of speech sounds.  When one\nof a hundred “sound peaks” is altered by an electrical\npop or crackle, the sound of an E does not suddenly\nchange to that of a U; it simply sounds like a\n“noisy E.”  If, on the other hand, speech contained\n“just enough” data, but no more, then the alteration\nof just one peak (or bit) would change the sound (or\ncharacter) entirely.  A moderately noisy phone line\nwould render messages as unintelligible gibberish\n(even those messages that did not start out that\nway!).  For this reason, when computers “talk” to\none another over communication lines in their\nhighly efficient system of beeps, conventional phone\nlines are seldom used, owing to the high error rate\nthat would result.  In any event, computers must use\nan elaborate method of double-checking transmitted\ndata, to ensure that no error is made.  In other\nwords, computers must introduce redundancy\nwhere none previously existed in order to communicate\neffectively.</p>\n<p>Predictability is closely related to redundancy.\nIf the recipient of a message (such as the reader of\ntext) is able to predict the next word before seeing\nit, the word is apparently not conveying any additional\ninformation.  In the following transmission, it\nis easy to predict the concluding letter: <em>WITH LIBERTY\nAND JUSTICE FOR AL</em>. (The transmission has almost\ncertainly not ended there!)  On the other hand, only\nthe most avid trivia buff could complete the sentence\n<em>HARRY TRUMAN'S HAT SIZE WAS</em>.....  While it is\nvery unlikely that the final word is giraffe, the correct\ncompletion of the sentence requires somewhat\nmore insight.  Similarly, the ability to infer the existence\nof an omitted letter or word (such as the indefinite\narticle) is a form of prediction.  It is hard to\nascertain the missing word in the sentence After\ncrash-landing on the planet Zartok, I saw the most\nenormous — I had ever seen!  The word in question\nis probably not portfolio.  But lack of familiarity with\nthe planet Zartok precludes a more accurate guess.\nAlthough these examples deal with predictability\nbased on semantic content, it is also possible to base\npredictions on patterns within the text itself.  In English,\na <em>Q</em> is almost never followed by anything but a\n<em>U</em>.  Also, the letter <em>E</em> is the most frequently used letter\nin English.  So if one had no other information\nwhatsoever about an omitted letter, guessing that\nthe letter might be E would probably be more reasonable\nthan guessing X.  And if the missing letter\nseemed to function as a vowel, the odds would be\ngreater still.  This is the type of predictability studied\nin information theory.</p>\n<p>Effective communication must contain the\n“right blend” of redundancy (predictability) and\nnew information (unpredictability).  If a message is\ntoo redundant, it becomes tiresome.  (This calls to\nmind a British comedy sketch in which an announcer\nspeaks on behalf of the <em>Society for People Who Say\nThings Twice Things Twice</em>.)  But as we have seen, if a\ncommuniqué has been compacted to maximize efficiency,\nthe listener must strive to receive each and\nevery morsel, a process which leaves no room for\nerror.  An analogy might be made with music.  If, on\nfirst hearing, a piece of music is entirely predictable,\ndroning on in endless clichés, then it lacks a certain\ncreative spark, and is not enjoyable.  Conversely, if\nthe listener continually finds himself disoriented\nwith each new note, unable to identify any underlying\npattern or theme, then the piece seems merely\na random collection of sounds and is equally uninteresting.\nSuch a composition would no doubt leave\nthe impression that the string section had suddenly\ncaught fire.</p>\n<p>Redundancy is itself a phenomenon worthy of\nstudy, independent of the study of language or music.\nThe physicist studies redundancy in the context\nof order and disorder of physical systems.  The disorder\nof a system is called its <em>entropy</em>.  The laws of\nthermodynamics tell us that closed systems tend to\nbecome more disorderly over time.  One such closed\nsystem is the universe itself.  We find that pockets of\nheat in the form of stars and galaxies are spreading\nout and cooling down over time.  Thus, we can imagine\na time in the distant future when the universe\nwill become almost uniformly cold, and very few\ntemperature gradients will exist which could serve\nto provide a source of usable energy, such as the\nsun.  Without being drawn into these difficult questions,\nwhich require many concepts and tools developed\nin information theory, suffice it to say that redundancy\nplays a central role in nature itself, and\nnot just in language.  As we have seen, redundancy\nis not the evil one might imagine it to be at first\nglance.  Indeed, it is necessary for the very existence\nof language.  But I repeat myself.</p>\n<h1></h1>",
  "preview": "<link rel=\"type\" href=\"Article\"> <h1 data-rel=\"title\">Redundancy in Natural Languages</h1> <p><em><span data-rel=\"author\">Steve Bonner</span> <span data-rel=\"location\">Germantown, Maryland</span></em></p> <p>In this fast-paced age when information is digitized,\nfaxed, uplinked, and downloaded, it is appropriate\nto consider natural languages from the\npoint of view of information theory.  That is, we examine\nthe information content of text or messages\nand the efficiency with which that information is\nrepresented.  The idea here is not to convert language\ninto some sort of highly efficient, but inhuman,\nstream of ones and zeroes!  That type of efficiency\nis fine for computers, but not for human\nbeings.  In fact, as we shall see, natural languages\ncontain a fair amount of redundancy.  While this\ndoes not provide us with the most concise form of\ncommunication possible, it is a form that is ideally\nsuited to human experience, which, after all, is why\nit came to be as it is.</p> <p>It cannot be denied that some words are simply\nlonger than they strictly need to be.  This is perhaps\nmore noticeable in German than in English.  In German,\nas new words are needed, they are often\nformed from smaller words already existing.  Thus,\nwe have the words <em>Haupthandelsartikel</em>, meaning\n'staple,' and <em>Autoreparaturwerkstatt</em>, meaning 'garage.'\nIf we were to construct a new vocabulary\nfrom scratch from the point of view of an extremely\norderly, but over-zealous, cataloguer, we might\nhave as the first two words in our dictionary <em>AAAA</em>\nand AAAB.  We would continue in this manner until\nwe reached our last two words, <em>ZZZY</em> and <em>ZZZZ</em>.\nOur dictionary would contain 456,976 words.  This\nlexicon is of sufficient size to form a rich written\nlanguage, such as German or English.  In fact, we\ncould associate to each English word one of our new\nwords.  Thus, the phrase <em>To be, or not to be</em>?  might\nbecome <em>THJL BDMN, OQRA NOOP THJL BDMN?</em>\n(So much for pronounceability!)  Of course, in this\nexample, our two-letter words become four-letter\nwords, which hasn't helped keep things concise.  But\nnow there is no word longer than four letters.  This\ngame of re-cataloguing all our words undoes a natural\nprocess which occurs as languages evolve.  This is\nthe tendency to shorten frequently used words and\nto allow less frequently used words to become\nlonger.  This trend, known as <em>Zipf's Law</em>, causes\ncommon words such as <em>to, in, a</em>, and it to be as short\nas they are.  It would be unthinkable to replace\nthese with ten-letter variants!  In this way, language\nat least attempts to follow a path of least resistance,\nin which the effort expended in writing or speech is\nlessened.</p> <p>Despite the economies of effort introduced by\nZipf's Law, natural languages nonetheless contain\nredundancies.  One example is the indefinite article\n<em>a</em> in English.  Many languages are inflected, which is\nalso a form of redundancy, since English gets by\nnicely with little inflection.  In English, the function\nof words within sentences is typically signaled by\nword order.  The sentences <em>I threw the dog the ball</em>\nand <em>I threw the ball the dog</em> are not equivalent.\nHere, some of the semantic information is provided\nby word order, and not simply from the words themselves.\nIn an inflected language, endings affixed to\nthe words for <em>dog</em> and <em>ball</em> indicate which object is\ndirect and which is indirect.  Thus, it is possible to\nrearrange words as in the example above.  The result\nmay not always be idiomatic, but it will probably get\nthe point across.  Such flexibility allows for a greater\ndegree of expression in poetry, for example.  Thus,\none has a romantic poem written in Latin in which\nthe first line contains the words for <em>man</em> and <em>woman</em>\non opposite ends of the line.  By the end of the\npoem, the words have gravitated toward the middle\nof the line.  It can even be argued that word forms\nused to show tense are superfluous, since Chinese\nhas no notion of tense.  A sentence may be in the\npast, present, or future, depending on context.  One\nwonders how a person translating into Chinese\nwould deal with unexpected or unpredictable tense\nshifts: <em>Veni, video, vincam!</em></p>"
}